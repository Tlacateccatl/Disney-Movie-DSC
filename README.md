# Disney Movie Web Scrap and Analysis
Disney Dataset Creation using Python BeautifulSoup.

## Context 
Disney Dataset Creation using Python BeautifulSoup. In this notebook data is scraped and cleaned, to create a list of Disney Film Wikipedia pages producing a dataset to further analyze.  In this repo I scrape Wikipedia pages to create a dataset on Disney Corporation Movies.

In this notebook data is scraped and cleaned, to create a list of Disney Film Wikipedia pages producing a dataset to further analyze.

In this repo I scrape Wikipedia pages to create a dataset on Disney Corporation Movies. I cover a wide range of Python & data science topics in this repo:
* Web scraping with BeautifulSoup
- Cleaning data
- Testing code with Pytest
- Pattern matching with regular expressions (Re library)
- Working with dates (datetime library)
- Saving & loading data with Pickle library
- Accessing data from an API using Requests library.
***

## Install
This project requires Python 3 and the following Python libraries installed:

- [NumPy](http://www.numpy.org/)
- [Pandas](http://pandas.pydata.org)
- [matplotlib](http://matplotlib.org/)
- [Basemap](http://matplotlib.org/basemap/)

You will also need to have software installed to run and execute a [Jupyter Notebook](http://ipython.org/notebook.html)

If you do not have Python installed yet, it is highly recommended that you install the [Anaconda](http://continuum.io/downloads) distribution of Python, which already has the above packages and more included. Make sure that you select the Python 3.x installer.

## Code
All the code is in the notebook `DisneyDataSet..ipynb`.

## Run
In a terminal or command window, navigate to the top-level project directory titanic_survival_exploration/ (that contains this README) and run one of the following commands:

```
jupyter notebook DisneyDataSet.ipynb
```

or
```
ipython notebook DisneyDataSet..ipynb
```
This will open the Jupyter Notebook software and project file in your web browser.
